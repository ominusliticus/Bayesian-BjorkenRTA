{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For changing directories to C++ programming and runnning files\n",
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "# since using WSL2\n",
    "os.environ['MPLCONFIGDIR'] = '/tmp/'\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Typical functionality for data manipulation and generation of latin hypercube\n",
    "import numpy as np\n",
    "from pyDOE import lhs\n",
    "import emcee\n",
    "\n",
    "# Gaussian Process emulator \n",
    "import sklearn\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as gpr\n",
    "from sklearn.gaussian_process import kernels as krnl\n",
    "import scipy.special as special\n",
    "import scipy.stats as st\n",
    "from scipy import optimize\n",
    "from scipy.linalg import lapack\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "import seaborn as sns\n",
    "sns.set(\"notebook\")\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "# data storage\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My costumizations for plots\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif', 'serif':['Computer Modern Roman']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "def costumize_axis(ax, x_title, y_title):\n",
    "    ax.set_xlabel(x_title, fontsize=24)\n",
    "    ax.set_ylabel(y_title, fontsize=24)\n",
    "    ax.tick_params(axis='both', labelsize=18, top=True, right=True)\n",
    "    ax.tick_params(axis='both', which='major', direction='in', length=8)\n",
    "    ax.xaxis.set_minor_locator(tck.AutoMinorLocator())\n",
    "    ax.yaxis.set_minor_locator(tck.AutoMinorLocator())\n",
    "    ax.tick_params(axis='both', which='minor', direction='in', length=4, top=True, right=True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others costumizations for plots\n",
    "def hist_1d_2d(X, Y, nameX, nameY):\n",
    "    left, width = 0.1, 0.75\n",
    "    bottom, height = 0.1, 0.75\n",
    "    spacing = 0.005\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom + height + spacing, width, 0.15]\n",
    "    rect_histy = [left + width + spacing, bottom, 0.15, height]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax = fig.add_axes(rect_scatter)\n",
    "    ax1 = fig.add_axes(rect_histx, sharex=ax)\n",
    "    ax2 = fig.add_axes(rect_histy, sharey=ax)\n",
    "    costumize_axis(ax1, '', '')\n",
    "    costumize_axis(ax2, '', '')\n",
    "    ax1.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax2.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    ax.scatter(X, Y, color='blue')\n",
    "    ax1.hist(X, color='blue', density=True)\n",
    "    ax2.hist(Y, color='blue', orientation='horizontal', density=True)\n",
    "    costumize_axis(ax, nameX, nameY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model\n",
    "This was actually done in `C++`, and this bit of code interface with the executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintParametersFile(params_dict):\n",
    "    '''\n",
    "    Function ouputs file \"params.txt\" to the Code/util folder to be used by the\n",
    "    Code/build/exact_solution.x program\n",
    "    '''\n",
    "    os.chdir('/mnt/c/users/gil-c/Documents/Heinz_Research/TeX-Docs/Rough-Drafts/Bayesian-Toy-Model/Code/')\n",
    "    with open('./utils/params.txt', 'w') as fout:\n",
    "        fout.write(f'tau_0 {params_dict[\"tau_0\"]}\\n')\n",
    "        fout.write(f'Lambda_0 {params_dict[\"Lambda_0\"]}\\n')\n",
    "        fout.write(f'alpha_0 {params_dict[\"alpha_0\"]}\\n')\n",
    "        fout.write(f'xi_0 {params_dict[\"xi_0\"]}\\n')\n",
    "        fout.write(f'ul {params_dict[\"tau_f\"]}\\n')\n",
    "        fout.write(f'll {params_dict[\"tau_0\"]}\\n')\n",
    "        fout.write(f'mass {params_dict[\"mass\"]}\\n')\n",
    "        fout.write(f'eta_s {params_dict[\"eta_s\"]}\\n')\n",
    "        fout.write(f'pl0 {params_dict[\"pl0\"]}\\n')\n",
    "        fout.write(f'pt0 {params_dict[\"pt0\"]}\\n')\n",
    "        fout.write(f'TYPE {params_dict[\"hydro_type\"]}')\n",
    "    os.chdir('/mnt/c/users/gil-c/Documents/Heinz_Research/TeX-Docs/Rough-Drafts/Bayesian-Toy-Model/Code/scripts/')\n",
    "    return \n",
    "\n",
    "def RunHydroSimulation():\n",
    "    '''\n",
    "    Function calls the C++ excecutable that run hydro calculations\n",
    "    '''\n",
    "    os.chdir('../')\n",
    "    sp.run(['./build/exact_solution.x'], shell=True)\n",
    "    os.chdir('scripts/')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default values for parameters\n",
    "params = {\n",
    "    'tau_0': 0.1,\n",
    "    'Lambda_0': 1.647204044,\n",
    "    'xi_0': -0.8320365099,\n",
    "    'alpha_0': 0.654868759,\n",
    "    'tau_f': 12.1,\n",
    "    'mass': 1.015228426,\n",
    "    'eta_s': 0.23873241463784,\n",
    "    'pl0': 8.1705525351457684,\n",
    "    'pt0': 1.9875332965147663,\n",
    "    'hydro_type': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function run runs hydro code to generate simualtion results for a set of \n",
    "# given parameters\n",
    "def ProcessHydro(parameter_names, simulation_points, store_whole_file=False):\n",
    "    out_list = []\n",
    "    def GetFromOutputFiles(hydro_type):\n",
    "        if hydro_type == 0:\n",
    "            prefix = '../output/CE_hydro/'\n",
    "            suffix = ''\n",
    "        elif hydro_type == 1:\n",
    "            prefix = '../output/DNMR_hydro/'\n",
    "            suffix = ''\n",
    "        elif hydro_type == 2:\n",
    "            prefix = '../output/aniso_hydro/'\n",
    "            suffix = ''\n",
    "        elif hydro_type == 3:\n",
    "            prefix = '../output/aniso_hydro/'\n",
    "            suffix = '2'\n",
    "        \n",
    "        if store_whole_file:\n",
    "            f_e = open(prefix + 'e' + suffix + '_m=0.200GeV.dat', 'r').readlines()\n",
    "            f_pi = open(prefix + 'shear' + suffix + '_m=0.200GeV.dat', 'r').readlines()\n",
    "            f_Pi = open(prefix + 'bulk' + suffix + '_m=0.200GeV.dat', 'r').readlines()\n",
    "            \n",
    "            out_list = []\n",
    "            for i in range(len(f_e)):\n",
    "                tau, e, pi, Pi = f_e[i].split()[0], f_e[i].split()[1], f_pi[i].split()[1], f_Pi[i].split()[1]\n",
    "                out_list.append([float(tau), float(e), float(pi), float(Pi)])\n",
    "\n",
    "            return np.array(out_list)\n",
    "        else:\n",
    "            f_e = open(prefix + 'e' + suffix + '_m=0.200GeV.dat', 'r')\n",
    "            last_e = f_e.readlines()[-1]\n",
    "            tau, e = last_e.split()[0], last_e.split()[1]\n",
    "            f_e.close(); del last_e\n",
    "\n",
    "            f_pi = open(prefix + 'shear' + suffix + '_m=0.200GeV.dat', 'r')\n",
    "            last_pi = f_pi.readlines()[-1]\n",
    "            pi = last_pi.split()[1]\n",
    "            f_pi.close(); del last_pi\n",
    "\n",
    "            f_Pi = open(prefix + 'bulk' + suffix + '_m=0.200GeV.dat', 'r')\n",
    "            last_Pi = f_Pi.readlines()[-1]\n",
    "            Pi = last_Pi.split()[1]\n",
    "            f_Pi.close(); del last_Pi\n",
    "\n",
    "            temp_list = [float(tau), float(e), float(pi), float(Pi)]\n",
    "            return np.array(temp_list)\n",
    "\n",
    "    def GetExactResults():\n",
    "        f_exact = open('../output/exact/MCMC_calculation_moments.dat','r')\n",
    "        if store_whole_file:\n",
    "            return f_exact.readlines()\n",
    "        else:\n",
    "            t, e, pl, pt, p = f_exact.readlines()[-1].split()\n",
    "            pi = (float(pt) - float(pl)) / 1.5\n",
    "            Pi = (2 *  float(pt) + float(pl)) / 3 - float(p)\n",
    "            temp_list = [float(t), float(e), pi, Pi]\n",
    "            return temp_list\n",
    "\n",
    "    if len(simulation_points) > len(parameter_names):\n",
    "        for parameters in simulation_points:\n",
    "            for i, name in enumerate(parameter_names):\n",
    "                params[name] = parameters[i]\n",
    "            PrintParametersFile(params)\n",
    "            RunHydroSimulation()\n",
    "            if params['hydro_type'] == 4:\n",
    "                out_list.append(GetExactResults())\n",
    "            else:\n",
    "                out_list.append(GetFromOutputFiles(params['hydro_type']))\n",
    "\n",
    "    else:\n",
    "        for i, name in enumerate(parameter_names):\n",
    "            params[name] = simulation_points[i]\n",
    "        PrintParametersFile(params)\n",
    "        RunHydroSimulation()\n",
    "        if params['hydro_type'] == 4:\n",
    "            return np.array(GetExactResults())\n",
    "        else:\n",
    "            return np.array(GetFromOutputFiles(params['hydro_type']))\n",
    "\n",
    "    return np.array(out_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression\n",
    "The training points and validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation times for generation of psuedo data\n",
    "simulation_taus = np.array([5.1, 6.1, 7.1, 8.1, 9.1, 10.1, 11.1, 12.1])\n",
    "eta_s = 5.0 / (4 * np.pi)\n",
    "params['eta_s'] = eta_s\n",
    "params['hydro_type'] = 4;\n",
    "exact_out = []\n",
    "\n",
    "read_in_exact = True\n",
    "if read_in_exact:\n",
    "    with open('exact_output_various_times.dat','r') as f:\n",
    "        exact_out = np.array([[float(entry) for entry in line.split()] for line in f.readlines()])\n",
    "else:\n",
    "\n",
    "    # Need to improve to run calculation once, and then back track to the points we want to keep\n",
    "    for i, tau in enumerate(simulation_taus):\n",
    "        exact_out.append(ProcessHydro(['tau_f'], [tau]))\n",
    "    \n",
    "    with open('exact_output_various_times.dat','w') as f:\n",
    "        for i, tau in enumerate(simulation_taus):\n",
    "            for entry in exact_out[i]:\n",
    "                f.write(f'{entry} ')\n",
    "            if i != simulation_taus.size - 1:\n",
    "                f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define latin hypercube sampling points and then run hydrodynamic simulation for all.\n",
    "GP_parameter_names = ['eta_s','tau_0', 'Lambda_0', 'alpha_0', 'xi_0'] # Expand as needed\n",
    "GP_parameter_names_math = [r'$\\eta_s$', r'$\\tau_0$', r'$\\Lambda_0$', r'$\\alpha_0$', r'$\\xi_0$'] # Expand as needed\n",
    "num_parameters_in_GP = len(GP_parameter_names) # Should be minimum of two to take into account relaxation time constant and ending time\n",
    "# Make sure that order of ranges variable matches how they appear in names_of_GP_parameters\n",
    "GP_parameter_ranges = np.array([[1 / (4 * np.pi), 10 / (4 * np.pi)], [0.05, 0.15], [0.0, 5.0], [0.0, 2.0], [-1.0, 10.0]])\n",
    "num_design_points = 40 * num_parameters_in_GP\n",
    "unit = lhs(n=num_parameters_in_GP, samples=num_design_points, criterion='maximin')\n",
    "GP_design_points = GP_parameter_ranges[:, 0] + unit * (GP_parameter_ranges[:, 1] - GP_parameter_ranges[:, 0])\n",
    "GP_design_range = GP_parameter_ranges[:,1] - GP_parameter_ranges[:,0]\n",
    "print(GP_design_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# fig.patch.set_facecolor('white')\n",
    "# ax.scatter(GP_design_points[:, 0], GP_design_points[:, 1])\n",
    "# costumize_axis(ax, r'$\\eta/\\mathcal S$', r'$\\tau_f$ [fm/c]')\n",
    "\n",
    "hist_1d_2d(GP_design_points[:, 0], GP_design_points[:, 1], r'$\\eta/\\mathcal S$', r'$\\tau_0$ [fm/c]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ce = []    # 0\n",
    "# dnmr = []  # 1\n",
    "# vah = []   # 2\n",
    "# mvah = []  # 3\n",
    "hydro_mode = [0, 1, 2, 3]\n",
    "names = ['ce', 'dnmr', 'vah', 'mvah']\n",
    "read_in_simulation = True   # should false for first run\n",
    "if read_in_simulation:\n",
    "    with open('design_points_n=4.dat','r') as f:\n",
    "        GP_design_points = np.array([[float(entry) for entry in line.split()] for line in f.readlines()])\n",
    "\n",
    "    hydro_lists = dict((key, []) for key in names)\n",
    "\n",
    "    for j, tau in enumerate(simulation_taus):\n",
    "        for name in names:\n",
    "            with open(f'{name}_simulation_points_n=4_tau={tau}.dat', 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                hydro_lists[name].append(np.array([[float(entry) for entry in line.split()] for line in lines]))\n",
    "\n",
    "    full_simulations = dict((key, []) for key in names)\n",
    "    for k, name in enumerate(names):\n",
    "        for i, design_point in enumerate(GP_design_points):\n",
    "            with open(f'full_outputs/{name}_full_output_C={design_point}_n=4.dat', 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    temp = []\n",
    "                    for entry in line.split():\n",
    "                        temp.append(float(entry))\n",
    "                    full_simulations[name].append(temp)\n",
    "else:\n",
    "    global_last_output = dict((key, []) for key in names)\n",
    "    global_full_output = dict((key, []) for key in names)\n",
    "    \n",
    "    params['tau_f'] = simulation_taus[-1]\n",
    "\n",
    "    for i in range(4):\n",
    "        params['hydro_type'] = i\n",
    "        for design_point in GP_design_points:\n",
    "\n",
    "            tau_start = design_point[1] # starting time \n",
    "            delta_tau = tau_start / 20\n",
    "            stop_time_indices = np.floor((simulation_taus - np.full_like(simulation_taus, tau_start)) / delta_tau)\n",
    "\n",
    "            local_last_output = []\n",
    "            hydro_output = np.array(ProcessHydro(parameter_names=GP_parameter_names, simulation_points=design_point, store_whole_file=True))\n",
    "            for j in range(simulation_taus.size):\n",
    "                local_last_output.append(hydro_output[int(stop_time_indices[j]), :])\n",
    "            global_last_output[names[i]].append(local_last_output)\n",
    "            global_full_output[names[i]].append(hydro_output)   \n",
    "\n",
    "    print(os.getcwd())\n",
    "    with open('design_points_n=4.dat','w') as f:\n",
    "        for line in GP_design_points:\n",
    "            for entry in line:\n",
    "                f.write(f'{entry} ')\n",
    "            f.write(f'\\n')\n",
    "\n",
    "    for k, name in enumerate(names):\n",
    "        for j, tau in enumerate(simulation_taus):\n",
    "                with open(f'{name}_simulation_points_n=4_tau={tau}.dat', 'w') as f:\n",
    "                    for line in np.array(global_last_output[name])[:, j, :]:\n",
    "                        for entry in line:\n",
    "                            f.write(f'{entry} ')\n",
    "                        f.write('\\n')\n",
    "\n",
    "    for k, name in enumerate(names):\n",
    "        for i, design_point in enumerate(GP_design_points):\n",
    "            with open(f'full_outputs/{name}_full_output_C={design_point}_n=4.dat', 'w') as f:\n",
    "                for line in global_full_output[name][i]:\n",
    "                    for entry in line:\n",
    "                        f.write(f'{entry} ')\n",
    "                    f.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots of total output\n",
    "fig, ax = plt.subplots(1, 3, figsize=(30,10))\n",
    "fig.patch.set_facecolor('white')\n",
    "cmap = get_cmap(10, 'tab10')\n",
    "\n",
    "\n",
    "rand_int = np.random.randint(0, num_design_points)\n",
    "for i in range(3):\n",
    "    for j, name in enumerate(names):\n",
    "        data = np.array(full_simulations[name])\n",
    "        current_step = 0\n",
    "        for k in range(num_design_points):\n",
    "            tau_start = GP_design_points[k][1] # starting time \n",
    "            delta_tau = tau_start / 20\n",
    "            steps = int((simulation_taus[-1] - tau_start) / delta_tau)\n",
    "            if k == rand_int: \n",
    "                ax[i].plot(data[current_step : current_step + steps - 1, 0], data[current_step : current_step + steps - 1, i+1], lw=2, color=cmap(j), label=name)\n",
    "            else:\n",
    "                ax[i].plot(data[current_step : current_step + steps - 1, 0], data[current_step : current_step + steps - 1, i+1], color=cmap(j), alpha=0.1)\n",
    "\n",
    "            current_step += steps + 1\n",
    "costumize_axis(ax[0], r'$\\tau$ [fm/c]', r'$\\mathcal E$ [fm$^{-4}$]')\n",
    "costumize_axis(ax[1], r'$\\tau$ [fm/c]', r'$\\pi$ [fm$^{-4}$]')\n",
    "costumize_axis(ax[2], r'$\\tau$ [fm/c]', r'$\\Pi$ [fm$^{-4}$]')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].legend(loc='upper right', fontsize=25)\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig('plots/full_simulations_n=4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, name in enumerate(names):\n",
    "    print(np.any(np.isnan(hydro_lists[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_error = 1.0\n",
    "exact_error = alpha_error * exact_out[:, 1:4]\n",
    "exact_pseudo = np.array([[np.random.normal(loc=obv, scale=0.05 * obv) for obv in exact] for exact in exact_out])\n",
    "for i, tau in enumerate(simulation_taus):\n",
    "    exact_pseudo[i, 0] = tau\n",
    "exact_pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulators = {'ce': [], 'dnmr': [], 'vah': [], 'mvah': []}\n",
    "read_in_emulator = False\n",
    "if read_in_emulator:\n",
    "    pass\n",
    "else:\n",
    "    for hydro in emulators:\n",
    "        local_list = []\n",
    "        print('\\tTraining GP for ' + hydro)\n",
    "        for i in range(1, 4):\n",
    "            kernel = 1 * krnl.RBF(\n",
    "                length_scale=GP_design_range, \n",
    "                length_scale_bounds=np.outer(np.array(GP_design_range), (1e-5, 1e2))) #+ \\\n",
    "                # krnl.WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e1))\n",
    "            GPR = gpr(kernel=kernel, n_restarts_optimizer=20)\n",
    "            print('\\t\\tTraining GP:', i)\n",
    "            if hydro == 'ce':\n",
    "                GPR.fit(GP_design_points, ce_simulation[:,i].reshape(-1,1))\n",
    "                print('GP score: {:1.3f}'.format(GPR.score(GP_design_points, ce_simulation[:,i])))\n",
    "            elif hydro == 'dnmr':\n",
    "                GPR.fit(GP_design_points, dnmr_simulation[:,i].reshape(-1,1))\n",
    "                print('GP score: {:1.3f}'.format(GPR.score(GP_design_points, dnmr_simulation[:,i])))\n",
    "            elif hydro == 'vah':\n",
    "                GPR.fit(GP_design_points, vah_simulation[:,i].reshape(-1,1))\n",
    "                print('GP score: {:1.3f}'.format(GPR.score(GP_design_points, vah_simulation[:,i])))\n",
    "            elif hydro == 'mvah':\n",
    "                GPR.fit(GP_design_points, mvah_simulation[:,i].reshape(-1,1))\n",
    "                print('GP score: {:1.3f}'.format(GPR.score(GP_design_points, mvah_simulation[:,i])))\n",
    "            else:\n",
    "                print('Invalid hydro type')\n",
    "                break\n",
    "            local_list.append(GPR)\n",
    "        emulators[hydro] = local_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in emulators:\n",
    "    print(name)\n",
    "    for gp in emulators[name]:\n",
    "        print('\\t', gp.kernel.hyperparameters)\n",
    "    print('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "number_validation_points = 10\n",
    "validation_points = np.array(GP_parameter_ranges[:,0]) + np.random.rand(number_validation_points, num_parameters_in_GP) * GP_design_range\n",
    "# make sure all are evaulated at same time\n",
    "for i in range(number_validation_points):\n",
    "    validation_points[i, 1] = validation_points[0, 1]\n",
    "\n",
    "names = ['ce', 'dnmr','vah','mvah']\n",
    "\n",
    "validation_data = {}\n",
    "for i, name in enumerate(names):\n",
    "    params['hydro_type'] = i\n",
    "    validation_data[name] = ProcessHydro(GP_parameter_names, validation_points)\n",
    "\n",
    "GP_predictions = {'ce': [], 'dnmr': [], 'vah': [], 'mvah': []}\n",
    "for name in names:\n",
    "    for i in range(3):\n",
    "        GP_x_prediction, GP_x_err = emulators[name][i].predict(validation_points, return_std=True)\n",
    "        GP_predictions[name].append(np.hstack((GP_x_prediction, GP_x_err.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_predictions['ce'][2][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(40,30))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "names = ['ce', 'dnmr','vah','mvah']\n",
    "observables = [r'$\\mathcal E$ [fm$^{-1}$]', r'$\\pi$ [fm$^{-1}$]', r'$\\Pi$ [fm$^{-1}$]']\n",
    "for i, name in enumerate(names):\n",
    "    for j, observable in enumerate(observables):\n",
    "        ax[i, j].scatter(validation_points[:,0], np.array(validation_data[name])[:, j+1], lw=2, color='blue', label=name)\n",
    "        ax[i, j].fill_between(validation_points[:,0], GP_predictions[name][j][:, 0] + GP_predictions[name][j][:, 1], GP_predictions[name][j][:, 0] - GP_predictions[name][j][:, 1], color='red', alpha=0.5)\n",
    "        costumize_axis(ax[i, j], r'$\\eta_\\mathcal S$ ', observable)\n",
    "        ax[i, j].legend(loc=0, fontsize=25)\n",
    "        # if j == 0:\n",
    "        #     ax[i, j].set_xscale('log')\n",
    "        #     ax[i, j].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check error distribution to make sure it conforms to out assumptions\n",
    "number_validation_points = 100\n",
    "validation_points = np.array(GP_parameter_ranges[:,0]) + np.random.rand(number_validation_points, num_parameters_in_GP) * GP_design_range\n",
    "\n",
    "validate = False\n",
    "if validate:\n",
    "    validation_data = {}\n",
    "    for i, name in enumerate(names):\n",
    "        params['hydro_type'] = i\n",
    "        validation_data[name] = ProcessHydro(GP_parameter_names, validation_points)\n",
    "\n",
    "    GP_predictions = {'ce': [], 'dnmr': [], 'vah': [], 'mvah': []}\n",
    "    for name in names:\n",
    "        for i in range(3):\n",
    "            GP_x_prediction, GP_x_err = emulators[name][i].predict(validation_points, return_std=True)\n",
    "            GP_predictions[name].append(np.hstack((GP_x_prediction, GP_x_err.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate:\n",
    "    normalized_discrepenancy = {'ce': [], 'dnmr': [], 'vah': [], 'mvah': []}\n",
    "    for i, name in enumerate(names):\n",
    "        for j in range(3):\n",
    "            normalized_discrepenancy[name].append((GP_predictions[name][j][:,0] - np.array(validation_data[name])[:,j+1]) / GP_predictions[name][j][:,1])\n",
    "\n",
    "    residuals = {'ce': [], 'dnmr': [], 'vah': [], 'mvah': []}\n",
    "    for i, name in enumerate(names):\n",
    "        for j in range(3):\n",
    "            residuals[name].append((GP_predictions[name][j][:,0] - np.array(validation_data[name])[:,j+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate:\n",
    "    fig1, ax1 = plt.subplots(4, 3, figsize=(40, 30))\n",
    "    fig1.patch.set_facecolor('white')\n",
    "    for i, name in enumerate(names):\n",
    "        for j, observable in enumerate(observables):\n",
    "            ax1[i, j].hist(residuals[name][j],color='brown')\n",
    "            ax1[i, j].set_xlabel(observable)\n",
    "\n",
    "    fig2, ax2 = plt.subplots(4, 3, figsize=(40, 30))\n",
    "    fig2.patch.set_facecolor('white')\n",
    "    for i, name in enumerate(names):\n",
    "        for j, observable in enumerate(observables):\n",
    "            ax2[i, j].hist(normalized_discrepenancy[name][j], bins=15, range=[-3,3], color='brown')\n",
    "            ax2[i, j].set_xlabel(observable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_observable(model_parameters, hydro_name, GP_emulator):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ------------\n",
    "    model_parameters    - 1d-array like (n,) \n",
    "    hydro_name          - string\n",
    "    GP_emulator         - dictionary\n",
    "    '''\n",
    "    means = []\n",
    "    variances = []\n",
    "    for i in range(3):\n",
    "        prediction, error = GP_emulator[hydro_name][i].predict(np.array(model_parameters).reshape(-1, len(model_parameters)), return_std=True)\n",
    "        means.append(prediction)\n",
    "        variances.append(error ** 2)\n",
    "    return np.hstack(means), np.diag(np.array(variances).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "The usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_parameters = GP_parameter_ranges[:,0] + np.random.rand(1) * GP_design_range\n",
    "params['hydro_type'] = 4\n",
    "true_observables = ProcessHydro(GP_parameter_names, true_parameters)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_parameters)\n",
    "print(true_observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(model_parameters, design_range):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ------------\n",
    "    model_parameters    - 1d-array with shape (n,). Value of parameters used to evaluate model\n",
    "    design_range        - 2d-array with shape (n,2). Give upper and lower limits of parameter values\n",
    "    '''\n",
    "    X  = np.array(model_parameters).reshape(1,-1)\n",
    "    lower = np.all(X >= np.array(design_range)[:,0])\n",
    "    upper = np.all(X <= np.array(design_range)[:,1])\n",
    "\n",
    "    if (lower and upper):\n",
    "        return 0\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "def log_likelihood(y, cov):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ------------\n",
    "    y   - 1d-array with shape (n,)\n",
    "    cov - 2d-array with shape (n,n)\n",
    "    '''\n",
    "    # Use Cholesky decomposition for efficient lin alg algo\n",
    "    L, info = lapack.dpotrf(cov, clean=True)\n",
    "\n",
    "    if (info < 0):\n",
    "        raise print('Error occured in computation of Cholesky decomposition')\n",
    "\n",
    "    # Solve equation L*b=y\n",
    "    b, info = lapack.dpotrs(L, np.array(y))\n",
    "\n",
    "    if (info != 0):\n",
    "        raise print('Error in inverting matrix equation')\n",
    "\n",
    "    if np.all(L.diagonal() > 0):\n",
    "        return -0.5 * np.dot(y, b) - np.log(L.diagonal()).sum()\n",
    "    else:\n",
    "        raise print('Diagonal has negative entry')\n",
    "\n",
    "def log_posterior(model_parameters, design_range, true_values, hydro_name, GP_emulator):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ------------\n",
    "    model_parameters    - 1d-array like (n,)\n",
    "    design_range        - 2d-array like (n,2)\n",
    "    true_values         - 1d-array like (3,) or 2d-array like (3,2)\n",
    "    hydro_name          - string containing hydro theory: 'ce', 'dnmr', 'vah', 'mvah'\n",
    "    GP_emulatr          - dictionary(hydro_name: emulator_list), \n",
    "                            emulator_list[0] - energery density\n",
    "                            emulator_list[1] - shear stress\n",
    "                            emulator_list[2] - bulk stress\n",
    "    '''\n",
    "    emulation_values, emulation_error = predict_observable(model_parameters, hydro_name, GP_emulator)\n",
    "\n",
    "    if np.array(true_values).shape != (3,2):\n",
    "        y = np.array(emulation_values) - np.array(true_values)\n",
    "        cov = emulation_error\n",
    "\n",
    "    return log_prior(model_parameters, design_range) + log_likelihood(y.flatten(), cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparams = len(GP_parameter_names)\n",
    "nwalkers = 20 * nparams\n",
    "nburn = 1000\n",
    "nsteps = 10000\n",
    "\n",
    "names = ['ce', 'dnmr', 'vah', 'mvah']\n",
    "MCMC_samplers = {}\n",
    "for i, name in enumerate(names):\n",
    "    print(f\"Computing for hydro theory: {name}\")\n",
    "    starting_guesses = GP_parameter_ranges[:,0] + np.random.rand(nwalkers, nparams) * GP_design_range\n",
    "    print(\"MCMC sampling using emcee (affine-invariant ensamble sampler) with {0} walkers\".format(nwalkers))\n",
    "    with Pool() as pool:\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, nparams, log_posterior, args=(GP_parameter_ranges, true_observables[name][0,1:4], name, emulators))\n",
    "        print('burn in sampling started')    \n",
    "        pos = sampler.run_mcmc(starting_guesses, nburn, progress=True, store=True)\n",
    "        print(\"Mean acceptance fraction: {0:.3f} (in total {1} steps)\".format(\n",
    "                        np.mean(sampler.acceptance_fraction), nwalkers*nburn))\n",
    "        print('Burn in completed.')\n",
    "        print(\"Now running the samples\")\n",
    "        sampler.run_mcmc(initial_state=None, nsteps=nsteps, progress=True, tune=False)  \n",
    "        print(\"Mean acceptance fraction: {0:.3f} (in total {1} steps)\".format(\n",
    "                        np.mean(sampler.acceptance_fraction), nwalkers*nsteps))\n",
    "    sampler_df = pd.DataFrame(sampler.get_chain(flat=True, discard=nburn), columns=GP_parameter_names_math)\n",
    "    MCMC_samplers[name] = sampler_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_parameter_names_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(chain, max_lag=100):\n",
    "    dim = len(chain)\n",
    "    acorr = np.empty(max_lag+1)\n",
    "    if max_lag > dim / 5:\n",
    "        print('max_lag is more than a 5th the chain length')\n",
    "    \n",
    "    chain1d = chain - np.average(chain)\n",
    "    for lag in range(max_lag + 1):\n",
    "        unshifted = None\n",
    "        shifted = chain1d[lag:]\n",
    "        if lag == 0:\n",
    "            unshifted = chain1d\n",
    "        else:\n",
    "            unshifted = chain1d[:-lag]\n",
    "        normalization = np.sqrt(np.dot(unshifted, unshifted))\n",
    "        normalization *= np.sqrt(np.dot(shifted, shifted))\n",
    "        acorr[lag] = np.dot(shifted, unshifted) / normalization\n",
    "    return acorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(40, 20))\n",
    "fig.patch.set_facecolor('white')\n",
    "for irow, name in enumerate(names):\n",
    "    for jcol, param in enumerate(GP_parameter_names_math):\n",
    "        acorr = autocorrelation(MCMC_samplers[name].iloc[:,jcol].to_numpy(), 2000)\n",
    "        ax[irow, jcol].plot(acorr)\n",
    "        costumize_axis(ax[irow, jcol], 'lag', 'autocorrelation(' + param + ')')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ce', 'dnmr', 'vah', 'mvah']\n",
    "for i, name in enumerate(names):\n",
    "    g = sns.PairGrid(MCMC_samplers[name].iloc[:,:], corner=True, diag_sharey=False)\n",
    "    g.map_lower(sns.histplot, bins=50, color=sns.color_palette()[9])\n",
    "    g.map_diag(sns.kdeplot, linewidth=2, shade=True, color=sns.color_palette()[-1])\n",
    "    for n in range(nparams):\n",
    "        ax=g.axes[n][n]\n",
    "        ax.axvline(x=true_parameters[n], ls='-', c=sns.color_palette()[3], label='Truth')\n",
    "        ax.text(0,0.8,s= f'{true_parameters[n]:.2f}', transform=ax.transAxes, color=sns.color_palette()[1], fontsize=12)\n",
    "    g.axes[1,1].legend(loc='best', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9dcb5d757abc08f80c32e5cf6b134b847ce902aef6cf0ef93f55126bf17cd8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('nucl-research': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
